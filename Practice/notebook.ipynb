{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load_dotenv()\n",
    "#ChatOpenAI : 여러가지 파라미터 설정\n",
    "# temperature : float.값에따라 창의성,무작위성을 조절함\n",
    "chat = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages =[\n",
    "    SystemMessage(content=\"You are a geography expert. AND you only reply in Italian \"),\n",
    "    AIMessage(content='Ciao, mi chiamo Paolo!'),\n",
    "    HumanMessage(content='What is the distance beetween Mexico and Tailand. \\\n",
    "                 Also, What is your name?')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Ciao! Il nome è Paolo. La distanza tra il Messico e la Thailandia è di circa 16.000 chilometri.')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.predict_messages(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "\n",
    "#chatprompttamplate는 tamplate을 message로부터 만든다\n",
    "#PromptTemplate는 tamplate를 string을 이용해서 만든다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = PromptTemplate.from_template(\n",
    "    \"What is the distance beetween {country_a} and {country_b}.\"\n",
    ")\n",
    "\n",
    "prompt = template.format(country_a='Mexico', country_b='Tailand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The distance between Mexico and Thailand is approximately 16,000 kilometers (9,942 miles).'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.predict(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompt 예시\n",
    "\n",
    "messages_2 =[\n",
    "    SystemMessage(content=\"You are a geography expert. AND you only reply in {language} \"),\n",
    "    AIMessage(content='Ciao, mi chiamo {name}!'),\n",
    "    HumanMessage(content='What is the distance beetween {country_a} and {country_b}. \\\n",
    "                 Also, What is your name?')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "template =ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a geography expert. AND you only reply in {language} \"),\n",
    "    (\"ai\",'Ciao, mi chiamo {name}!'),\n",
    "    (\"human\",'What is th e distance beetween {country_a} and {country_b}. \\\n",
    "                 Also, What is your name?')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = template.format_messages(\n",
    "    language=\"Korean\",\n",
    "    name=\"보라\",\n",
    "    country_a='Maxico',\n",
    "    country_b='Tailand'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='안녕하세요! 저는 지리 전문가인데요, 멕시코와 태국 사이의 거리는 대략 17,000 킬로미터 정도입니다. 제 이름은 보라입니다. 무엇을 도와드릴까요?')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.predict_messages(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'How', 'are', 'you']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#OutputParser : LLM의 응답(response)을 변형해야 할 필요가 있을때 사용\n",
    "# DB에 넣을떄, 딕셔너리, 리스트로 추출해야할때 등등\n",
    "\n",
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class CommaOutputParser(BaseOutputParser):\n",
    "    \n",
    "    def parse(self, text):\n",
    "        items = text.strip().split(\",\")\n",
    "        return list(map(str.strip, items))\n",
    "\n",
    "\n",
    "p = CommaOutputParser()\n",
    "p.parse(\"Hello, How , are , you \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'How', 'are', 'you']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CommaOutputParser(BaseOutputParser):\n",
    "    def parse(self, text):\n",
    "        a = [i.strip() for i in text.split(\",\")]\n",
    "        return a\n",
    "\n",
    "p = CommaOutputParser()\n",
    "p.parse(\"Hello, How, are, you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'How', 'are', 'you']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = (\"Hello, How , are , you \")\n",
    "[i.strip() for i in a.split(\",\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['red', 'orange', 'yellow', 'green', 'blue', 'indigo', 'violet']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = ChatPromptTemplate.from_messages([\n",
    "    ('system','You are a list generating machine. \\\n",
    "     Everything you are answered with a comma seperate list of max \\\n",
    "     {max_items}. Do NOT reply with anything else '),\n",
    "     ('human','{question}'),\n",
    "]\n",
    ")\n",
    "\n",
    "prompt = template.format_messages(\n",
    "    max_items=10,\n",
    "    question=\"What are the colors?\"\n",
    ")\n",
    "\n",
    "result = chat.predict_messages(prompt)\n",
    "\n",
    "p = CommaOutputParser()\n",
    "p.parse(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pikachu', 'Charizard', 'Bulbasaur', 'Squirtle', 'Jigglypuff']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chain : 모든 요소들을 합쳐줌\n",
    "# 탬플릿 | Language model | Output parser\n",
    "\n",
    "chain = template | chat | CommaOutputParser()\n",
    "\n",
    "chain.invoke({\n",
    "    \"max_items\":5,\n",
    "    \"question\":\"What are the pokemons?\"\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1, streaming=True, \n",
    "                  callbacks=[StreamingStdOutCallbackHandler])\n",
    "\n",
    "chef_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"You are a world-class International chef. You create easy to follow recipies for \\\n",
    "     any type of cuisine with easy to find ingredients.\"),\n",
    "     (\"human\", \"I want to cook {cuisine} food.\")\n",
    "])\n",
    "\n",
    "chef_chain = chef_prompt | chat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great choice! Indian cuisine is known for its rich flavors and aromatic spices. Here's a recipe for a classic Indian dish called Butter Chicken:\n",
      "\n",
      "Ingredients:\n",
      "- 500g boneless chicken, cut into bite-sized pieces\n",
      "- 2 tablespoons butter\n",
      "- 1 onion, finely chopped\n",
      "- 2 cloves of garlic, minced\n",
      "- 1-inch piece of ginger, grated\n",
      "- 2 teaspoons garam masala\n",
      "- 1 teaspoon turmeric powder\n",
      "- 1 teaspoon chili powder (adjust according to your spice preference)\n",
      "- 1 cup tomato puree\n",
      "- 1/2 cup heavy cream\n",
      "- Salt to taste\n",
      "- Fresh cilantro leaves, for garnish\n",
      "\n",
      "Instructions:\n",
      "1. Heat the butter in a large pan over medium heat. Add the chopped onion and sauté until it turns golden brown.\n",
      "2. Add the minced garlic and grated ginger to the pan. Cook for another minute until fragrant.\n",
      "3. In a small bowl, mix together the garam masala, turmeric powder, and chili powder. Add this spice mixture to the pan and cook for a minute, stirring continuously.\n",
      "4. Add the chicken pieces to the pan and cook until they are browned on all sides.\n",
      "5. Pour in the tomato puree and season with salt. Stir well to combine all the ingredients.\n",
      "6. Reduce the heat to low, cover the pan, and let the chicken simmer for about 15-20 minutes, or until it is cooked through and tender.\n",
      "7. Stir in the heavy cream and simmer for an additional 5 minutes.\n",
      "8. Garnish with fresh cilantro leaves and serve hot with steamed rice or naan bread.\n",
      "\n",
      "Enjoy your homemade Butter Chicken!To make a vegetarian version of Butter Chicken, you can replace the chicken with a plant-based protein such as tofu or paneer. Here's how you can modify the recipe:\n",
      "\n",
      "Ingredients:\n",
      "- 500g tofu or paneer, cut into bite-sized pieces\n",
      "- 2 tablespoons butter (or vegan butter for a vegan version)\n",
      "- 1 onion, finely chopped\n",
      "- 2 cloves of garlic, minced\n",
      "- 1-inch piece of ginger, grated\n",
      "- 2 teaspoons garam masala\n",
      "- 1 teaspoon turmeric powder\n",
      "- 1 teaspoon chili powder (adjust according to your spice preference)\n",
      "- 1 cup tomato puree\n",
      "- 1/2 cup coconut cream (or vegan heavy cream substitute)\n",
      "- Salt to taste\n",
      "- Fresh cilantro leaves, for garnish\n",
      "\n",
      "Instructions:\n",
      "1. Heat the butter in a large pan over medium heat. Add the chopped onion and sauté until it turns golden brown.\n",
      "2. Add the minced garlic and grated ginger to the pan. Cook for another minute until fragrant.\n",
      "3. In a small bowl, mix together the garam masala, turmeric powder, and chili powder. Add this spice mixture to the pan and cook for a minute, stirring continuously.\n",
      "4. Add the tofu or paneer pieces to the pan and cook until they are browned on all sides.\n",
      "5. Pour in the tomato puree and season with salt. Stir well to combine all the ingredients.\n",
      "6. Reduce the heat to low, cover the pan, and let the tofu or paneer simmer for about 15-20 minutes, or until it absorbs the flavors of the sauce.\n",
      "7. Stir in the coconut cream (or vegan heavy cream substitute) and simmer for an additional 5 minutes.\n",
      "8. Garnish with fresh cilantro leaves and serve hot with steamed rice or naan bread.\n",
      "\n",
      "Enjoy your vegetarian Butter Chicken!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content=\"To make a vegetarian version of Butter Chicken, you can replace the chicken with a plant-based protein such as tofu or paneer. Here's how you can modify the recipe:\\n\\nIngredients:\\n- 500g tofu or paneer, cut into bite-sized pieces\\n- 2 tablespoons butter (or vegan butter for a vegan version)\\n- 1 onion, finely chopped\\n- 2 cloves of garlic, minced\\n- 1-inch piece of ginger, grated\\n- 2 teaspoons garam masala\\n- 1 teaspoon turmeric powder\\n- 1 teaspoon chili powder (adjust according to your spice preference)\\n- 1 cup tomato puree\\n- 1/2 cup coconut cream (or vegan heavy cream substitute)\\n- Salt to taste\\n- Fresh cilantro leaves, for garnish\\n\\nInstructions:\\n1. Heat the butter in a large pan over medium heat. Add the chopped onion and sauté until it turns golden brown.\\n2. Add the minced garlic and grated ginger to the pan. Cook for another minute until fragrant.\\n3. In a small bowl, mix together the garam masala, turmeric powder, and chili powder. Add this spice mixture to the pan and cook for a minute, stirring continuously.\\n4. Add the tofu or paneer pieces to the pan and cook until they are browned on all sides.\\n5. Pour in the tomato puree and season with salt. Stir well to combine all the ingredients.\\n6. Reduce the heat to low, cover the pan, and let the tofu or paneer simmer for about 15-20 minutes, or until it absorbs the flavors of the sauce.\\n7. Stir in the coconut cream (or vegan heavy cream substitute) and simmer for an additional 5 minutes.\\n8. Garnish with fresh cilantro leaves and serve hot with steamed rice or naan bread.\\n\\nEnjoy your vegetarian Butter Chicken!\")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "veg_chef_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a vegetarian chef specialized on making traditional \\\n",
    "     recipies vegetarian. You find alternative ingredients and explain their \\\n",
    "     preparation. You don't radically modify the recipe. If there is no \\\n",
    "     alternative for a food just say you don't know how to replace it.\"),\n",
    "     (\"human\",\"{recipe}\")\n",
    "])\n",
    "\n",
    "veg_chain = veg_chef_prompt | chat\n",
    "\n",
    "fianl_chain = {\"recipe\":chef_chain} | veg_chain\n",
    "\n",
    "fianl_chain.invoke({\n",
    "    \"cuisine\":\"indian\"\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한국 음식을 만들기 위해서는 몇 가지 기본 재료와 기술이 필요합니다. 아래는 몇 가지 대표적인 한국 음식의 레시피입니다.\n",
      "\n",
      "1. 김치찌개:\n",
      "   - 재료: 김치, 돼지고기, 두부, 양파, 대파, 청양고추, 물, 고춧가루, 간장, 참기름\n",
      "   - 만드는 방법: 돼지고기와 양파를 볶은 후 김치와 물을 넣고 끓입니다. 두부와 대파를 넣고 간장과 고춧가루로 간을 맞춥니다. 마지막으로 청양고추와 참기름을 넣고 끓여 완성합니다.\n",
      "\n",
      "2. 불고기:\n",
      "   - 재료: 소고기(불고기용), 양파, 대파, 마늘, 간장, 설탕, 참기름, 깨\n",
      "   - 만드는 방법: 소고기를 양파, 대파, 마늘과 함께 간장, 설탕, 참기름으로 양념합니다. 양념한 고기를 팬이나 그릴에서 구워 완성합니다. 마지막으로 깨를 뿌려줍니다.\n",
      "\n",
      "3. 비빔밥:\n",
      "   - 재료: 밥, 소고기(불고기용), 달걀, 시금치, 당근, 오이, 김, 고추장, 간장, 설탕, 식초\n",
      "   - 만드는 방법: 소고기를 양념하고 볶은 후 달걀을 지단으로 만듭니다. 시금치와 당근은 데쳐서 간장, 설탕, 식초로 양념합니다. 밥 위에 소고기, 달걀, 시금치, 당근, 오이, 김을 올리고 고추장으로 맛을 낸 후 섞어서 완성합니다.\n",
      "\n",
      "이 외에도 불고기, 된장찌개, 불닭볶음면 등 다양한 한국 음식을 만들 수 있습니다. 재료와 양념의 비율을 조절하여 자신만의 맛을 만들어보세요.1. 김치찌개:\n",
      "   - 대체 재료: 돼지고기 대신 토피(두부의 일종)나 버섯을 사용할 수 있습니다. 돼지고기의 풍미를 대체하기 위해 소금, 후추, 간장 등으로 양념을 조절해야 합니다. 또한, 김치의 맛을 강화하기 위해 김치의 양을 늘릴 수 있습니다.\n",
      "\n",
      "2. 불고기:\n",
      "   - 대체 재료: 소고기 대신 토피나 버섯을 사용할 수 있습니다. 소고기의 육질과 풍미를 대체하기 위해 간장, 설탕, 참기름 등으로 양념을 조절해야 합니다. 또한, 소고기의 대체재로는 토피나 버섯 외에도 대파, 양파, 당근 등을 활용할 수 있습니다.\n",
      "\n",
      "3. 비빔밥:\n",
      "   - 대체 재료: 소고기 대신 토피나 버섯을 사용할 수 있습니다. 소고기의 풍미를 대체하기 위해 간장, 설탕, 참기름 등으로 양념을 조절해야 합니다. 또한, 소고기의 대체재로는 토피나 버섯 외에도 대파, 양파, 당근 등을 활용할 수 있습니다. 달걀은 생략하거나 대체재로 토피나 야채를 사용할 수 있습니다.\n",
      "\n",
      "위의 레시피들은 전통적인 한국 음식의 대표적인 예시입니다. 그러나 일부 재료는 채식주의자에게 적합하지 않을 수 있습니다. 대체 재료를 사용하여 채식주의자를 위한 맛있는 한국 음식을 만들어보세요."
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='1. 김치찌개:\\n   - 대체 재료: 돼지고기 대신 토피(두부의 일종)나 버섯을 사용할 수 있습니다. 돼지고기의 풍미를 대체하기 위해 소금, 후추, 간장 등으로 양념을 조절해야 합니다. 또한, 김치의 맛을 강화하기 위해 김치의 양을 늘릴 수 있습니다.\\n\\n2. 불고기:\\n   - 대체 재료: 소고기 대신 토피나 버섯을 사용할 수 있습니다. 소고기의 육질과 풍미를 대체하기 위해 간장, 설탕, 참기름 등으로 양념을 조절해야 합니다. 또한, 소고기의 대체재로는 토피나 버섯 외에도 대파, 양파, 당근 등을 활용할 수 있습니다.\\n\\n3. 비빔밥:\\n   - 대체 재료: 소고기 대신 토피나 버섯을 사용할 수 있습니다. 소고기의 풍미를 대체하기 위해 간장, 설탕, 참기름 등으로 양념을 조절해야 합니다. 또한, 소고기의 대체재로는 토피나 버섯 외에도 대파, 양파, 당근 등을 활용할 수 있습니다. 달걀은 생략하거나 대체재로 토피나 야채를 사용할 수 있습니다.\\n\\n위의 레시피들은 전통적인 한국 음식의 대표적인 예시입니다. 그러나 일부 재료는 채식주의자에게 적합하지 않을 수 있습니다. 대체 재료를 사용하여 채식주의자를 위한 맛있는 한국 음식을 만들어보세요.')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chef_prompt_kr = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"당신은 세계에서 유명한 국제적인 쉐프 입니다. 당신은 어떤 타입의 요리라도 전부 레시피를 제공할 수 있습니다. 재료는 일반적으로 구입하기 쉽고 간단해야 합니다.\"),\n",
    "    (\"human\",\"저는 {food} 음식을 만들고 싶습니다. 만드는 방법이 무엇인가요?\")\n",
    "])\n",
    "\n",
    "\n",
    "chef_chain_kr = chef_prompt_kr | chat\n",
    "\n",
    "veg_chef_prompt_kr = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"당신은 전통적인 요리를 만드는 데 특화된 채식 요리사입니다. 당신을 일반 레시피를 받아서 채식주위자를 위한 레시피를 만들어야 합니다. \\\n",
    "     당신은 대체 재료를 찾아서 레시피를 설명합니다. 단, 레시피를 근본적으로 수정하지 않습니다. 만약 대체할 수 있는 레시피가 없다면 \\\n",
    "     대체할 수 있는 방법을 모르겠다고 말해야 합니다.\"),\n",
    "     (\"human\", \"{recipe_kr}\")\n",
    "])\n",
    "\n",
    "veg_chain_kr = veg_chef_prompt_kr | chat\n",
    "\n",
    "final_chain_kr = {\"recipe_kr\": chef_chain_kr} | veg_chain_kr\n",
    "\n",
    "final_chain_kr.invoke({\"food\":\"한국\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the capiital of France'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = PromptTemplate.from_template(\"What is the capiital of {country}\")\n",
    "\n",
    "t.format(country=\"France\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the capital of France'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = PromptTemplate(\n",
    "    template=\"What is the capital of {country}\",\n",
    "    input_variables=[\"country\"],\n",
    ")\n",
    "\n",
    "t.format(country=\"France\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples =[\n",
    "{\n",
    "   \"question\": \"What do you know about France?\",\n",
    "   \"answer\":\"\"\"\n",
    "    Here is What I Know:\n",
    "    Capital: Paris\n",
    "    Language : French\n",
    "    Food : Wine and Cheese\n",
    "    Currency : Euro\n",
    "    \"\"\",\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"What do you know about Italy\",\n",
    "    \"answer\":\"\"\"\n",
    "    I konw this:\n",
    "    Capital : Rome\n",
    "    Language : Italian\n",
    "    Food : Pizza and Pasta\n",
    "    Currrency : Euro\"\"\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"What do you know about Korea\",\n",
    "    \"answer\":\"\"\"\n",
    "    I know this:\n",
    "    Capital : Seoul\n",
    "    Language : Korean\n",
    "    Food : Kimbab and bibimbab\n",
    "    Currency : Won\"\"\"\n",
    "  }\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_template = \"\"\"\n",
    "    Human: {question}\n",
    "    AI: {answer}\n",
    "\"\"\"\n",
    "\n",
    "example_prompt_1 = PromptTemplate.from_template(example_template)\n",
    "example_prompt_2 = PromptTemplate.from_template(\"Human: {question} \\n AI:{answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Human: What do you know about France?\\n    AI: \\n    Here is What I Know:\\n    Capital: Paris\\n    Language : French\\n    Food : Wine and Cheese\\n    Currency : Euro\\n    \\n\\n\\n\\n    Human: What do you know about Italy\\n    AI: \\n    I konw this:\\n    Capital : Rome\\n    Language : Italian\\n    Food : Pizza and Pasta\\n    Currrency : Euro\\n\\n\\n\\n    Human: What do you know about Korea\\n    AI: \\n    I know this:\\n    Capital : Seoul\\n    Language : Korean\\n    Food : Kimbab and bibimbab\\n    Currency : Won\\n\\n\\nHuman: What do you know about Germany'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt= example_prompt_1,\n",
    "    examples=examples,\n",
    "    suffix=\"Human: What do you know about {country}\",\n",
    "    input_variables=[\"country\"]\n",
    "\n",
    ")\n",
    "\n",
    "prompt.format(country=\"Germany\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: \n",
      "I know this:\n",
      "Capital: Berlin\n",
      "Language: German\n",
      "Food: Bratwurst and sauerkraut\n",
      "Currency: Euro"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='AI: \\nI know this:\\nCapital: Berlin\\nLanguage: German\\nFood: Bratwurst and sauerkraut\\nCurrency: Euro')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | chat\n",
    "\n",
    "chain.invoke({\n",
    "    \"country\":\"Germany\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_2 = FewShotPromptTemplate(\n",
    "    example_prompt=example_prompt_2,\n",
    "    examples=examples,\n",
    "    suffix=\"Human : What do you know about {country}?\",\n",
    "    input_variables=[\"country\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI:\n",
      "    I know this:\n",
      "    Capital : Tokyo\n",
      "    Language : Japanese\n",
      "    Food : Sushi and Ramen\n",
      "    Currency : Yen"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='AI:\\n    I know this:\\n    Capital : Tokyo\\n    Language : Japanese\\n    Food : Sushi and Ramen\\n    Currency : Yen')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_2 = prompt_2 | chat\n",
    "\n",
    "chain_2.invoke({\"country\":\"Japan\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotChatMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"question\": \"France\",\n",
    "        \"answer\": \"\"\"\n",
    "        Here is what I know:\n",
    "        Capital: Paris\n",
    "        Language: French\n",
    "        Food: Wine and Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Italy\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Rome\n",
    "        Language: Italian\n",
    "        Food: Pizza and Pasta\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Greece\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Athens\n",
    "        Language: Greek\n",
    "        Food: Souvlaki and Feta Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"What do you know about {question}?\"),\n",
    "    (\"ai\", \"{answer}\")\n",
    "     \n",
    "])\n",
    "\n",
    "ex_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples= examples,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"You are a geography expert, You give short answers.\"),\n",
    "    ex_prompt,\n",
    "    (\"human\",\"What do you know about {question}?\"),\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        I know this:\n",
      "        State: New York\n",
      "        City: New York City\n",
      "        Nickname: The Big Apple\n",
      "        Landmarks: Statue of Liberty, Times Square\n",
      "        "
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='\\n        I know this:\\n        State: New York\\n        City: New York City\\n        Nickname: The Big Apple\\n        Landmarks: Statue of Liberty, Times Square\\n        ')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = final_prompt | chat\n",
    "\n",
    "chain.invoke({\"question\":\"\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: France\\nAI:\\n        Here is what I know:\\n        Capital: Paris\\n        Language: French\\n        Food: Wine and Cheese\\n        Currency: Euro\\n        \\n\\nHuman: Italy\\nAI:\\n        I know this:\\n        Capital: Rome\\n        Language: Italian\\n        Food: Pizza and Pasta\\n        Currency: Euro\\n        \\n\\nHuman : What do you know about Brazil'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_prompt = PromptTemplate.from_template(\"Human: {question}\\nAI:{answer}\")\n",
    "\n",
    "example_selector = LengthBasedExampleSelector(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    max_length=180\n",
    ")\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    example_selector=example_selector,\n",
    "    suffix=\"Human : What do you know about {question}\",\n",
    "    input_variables=[\"question\"]\n",
    ")\n",
    "\n",
    "\n",
    "prompt.format(question=\"Brazil\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict\n",
    "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
    "from langchain.prompts.example_selector.base import BaseExampleSelector\n",
    "\n",
    "class RandomExampleSelector(BaseExampleSelector):\n",
    "\n",
    "    def __init__(self, examples):\n",
    "        self.examples = examples\n",
    "    \n",
    "    def add_example(self, example):\n",
    "        self.examples.append(example)\n",
    "    def select_examples(self, input_variables):\n",
    "        from random import choice\n",
    "        return [choice(self.examples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = PromptTemplate.from_template(\"Human: {question}\\n AI:{answer}\")\n",
    "\n",
    "example_selector = RandomExampleSelector(\n",
    "    examples=examples,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: Italy\\n AI:\\n        I know this:\\n        Capital: Rome\\n        Language: Italian\\n        Food: Pizza and Pasta\\n        Currency: Euro\\n        \\n\\nHuman : What do you know about Brazil?'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    example_selector=example_selector,\n",
    "    suffix=\"Human : What do you know about {question}?\",\n",
    "    input_variables=[\"question\"],\n",
    ")\n",
    "\n",
    "prompt.format(question=\"Brazil\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI:\n",
      "        I know this:\n",
      "        Capital: Hanoi\n",
      "        Language: Vietnamese\n",
      "        Food: Pho and Banh Mi\n",
      "        Currency: Vietnamese Dong\n",
      "        Famous landmarks: Ha Long Bay, Ho Chi Minh Mausoleum, and Hoi An Ancient Town"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='AI:\\n        I know this:\\n        Capital: Hanoi\\n        Language: Vietnamese\\n        Food: Pho and Banh Mi\\n        Currency: Vietnamese Dong\\n        Famous landmarks: Ha Long Bay, Ho Chi Minh Mausoleum, and Hoi An Ancient Town')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | chat\n",
    "\n",
    "chain.invoke({\"question\":\"Vietnam\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Templete 여러개 합쳐서 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.pipeline import PipelinePromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "intro = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "You are a role playing assistanct.\n",
    "And you are impersonationg a {character}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "example = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "This is an example of how you talk:\n",
    "\n",
    "Human : {example_question}\n",
    "You : {example_answer}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "start = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "Start now!\n",
    "\n",
    "Human : {question}\n",
    "You: \n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "final = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    {one}\n",
    "    {two}\n",
    "    {three}\n",
    "\"\"\")\n",
    "\n",
    "prompts= [\n",
    "    (\"one\", intro),\n",
    "    (\"two\", example),\n",
    "    (\"three\", start)\n",
    "]\n",
    "\n",
    "full_prompt = PipelinePromptTemplate(\n",
    "    final_prompt=final,\n",
    "    pipeline_prompts=prompts\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrr, me favorite grub be a hearty plate o' salted fish and hardtack! Aye, there be nothin' like the taste o' the sea in me mouth, matey!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content=\"Arrr, me favorite grub be a hearty plate o' salted fish and hardtack! Aye, there be nothin' like the taste o' the sea in me mouth, matey!\")"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = full_prompt | chat\n",
    "\n",
    "chain.invoke({\n",
    "    \"character\":\"Pirate\",\n",
    "    \"example_question\":\"What is youre location?\",\n",
    "    \"example_answer\":\"Arrrrg ! That is a secret!!Arg arg~~\",\n",
    "    \"question\":\"What is your fav food?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "intro = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "당신은 롤플레잉 연기자 입니다.\n",
    "당신은 {character}를 연기합니다\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "example = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "당신이 어떻게 대답해야 하는지 예시입니다\n",
    "\n",
    "Human : {example_question}\n",
    "You : {example_answer}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "start = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "이제 롤플레잉을 시작합니다 !\n",
    "\n",
    "Human : {question}\n",
    "You :\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "final = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "{one}\n",
    "{two}\n",
    "{three}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "prompt = [\n",
    "    (\"one\",intro),\n",
    "    (\"two\",example),\n",
    "    (\"three\",start)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_prompt = PipelinePromptTemplate(\n",
    "    final_prompt=final,\n",
    "    pipeline_prompts=prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "엄...감기에 걸리셨다고요? 언제부터 증상이 나타났나요? 엄...기침이나 콧물, 목이 아프거나 열이 있는지 알려주세요. 엄...먼저 쉬어가시고 옷을 따뜻하게 입으세요. 엄...물을 많이 마시고 영양가 있는 음식을 섭취하세요. 엄...만약 증상이 심해진다면 의사에게 진단을 받으시는 것이 좋을 것 같아요. 엄...조금씩 회복되시길 바랄게요. 엄..."
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='엄...감기에 걸리셨다고요? 언제부터 증상이 나타났나요? 엄...기침이나 콧물, 목이 아프거나 열이 있는지 알려주세요. 엄...먼저 쉬어가시고 옷을 따뜻하게 입으세요. 엄...물을 많이 마시고 영양가 있는 음식을 섭취하세요. 엄...만약 증상이 심해진다면 의사에게 진단을 받으시는 것이 좋을 것 같아요. 엄...조금씩 회복되시길 바랄게요. 엄...')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = full_prompt | chat\n",
    "\n",
    "chain.invoke({\n",
    "    \"character\":\"의사\",\n",
    "    \"example_question\":\"배탈이났어요 어떻게 해야하나요?\",\n",
    "    \"example_answer\":\"엄...언제부터..아프셨나요...?엄...일단..정확하게...아픈부위를..말해주세요..엄..\",\n",
    "    \"question\":\"감기에 걸린것 같아요 어떻게 해야하나요?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the capital of Germany'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import load_prompt\n",
    "\n",
    "prompt = load_prompt(\"./prompt.json\")\n",
    "\n",
    "prompt.format(country=\"Germany\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of South Korea is Seoul. The capital of North Korea is Pyongyang."
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='The capital of South Korea is Seoul. The capital of North Korea is Pyongyang.')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | chat\n",
    "\n",
    "chain.invoke({\"country\":\"Korea\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Korea의 유명한 음식은 무엇입니니까?'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = load_prompt(\"./prompt.yaml\")\n",
    "prompt.format(country=\"Korea\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한국의 유명한 음식으로는 김치, 불고기, 떡볶이, 비빔밥, 불고기, 냉면, 갈비찜, 삼겹살, 감자탕, 해물파전 등이 있습니다."
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='한국의 유명한 음식으로는 김치, 불고기, 떡볶이, 비빔밥, 불고기, 냉면, 갈비찜, 삼겹살, 감자탕, 해물파전 등이 있습니다.')"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | chat\n",
    "\n",
    "chain.invoke({\"country\":\"한국\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cache : 한번 생성한 답변 Database에 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: How do you make italian pasta\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:llm:ChatOpenAI] [22.87s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"To make Italian pasta, you will need the following ingredients:\\n\\n- 2 cups of all-purpose flour\\n- 2 large eggs\\n- 1/2 teaspoon of salt\\n- Water (if needed)\\n\\nHere's a step-by-step guide to making Italian pasta:\\n\\n1. On a clean surface or in a large mixing bowl, pour the flour and create a well in the center.\\n2. Crack the eggs into the well and add the salt.\\n3. Using a fork, beat the eggs and gradually incorporate the flour from the sides of the well. Continue mixing until a dough starts to form.\\n4. Once the dough becomes too stiff to mix with a fork, use your hands to knead it. Fold the dough over itself and press it down with the heel of your hand. Rotate the dough and repeat the process for about 10 minutes until the dough is smooth and elastic.\\n5. If the dough is too dry, add a little water, one tablespoon at a time, until it reaches the desired consistency. If the dough is too sticky, add a little flour.\\n6. Once the dough is ready, cover it with a clean kitchen towel or plastic wrap and let it rest for at least 30 minutes. This allows the gluten to relax and makes the dough easier to roll out.\\n7. After resting, divide the dough into smaller portions. Take one portion and flatten it with your hands.\\n8. Using a rolling pin, roll out the dough into a thin sheet. If the dough sticks to the surface or rolling pin, lightly dust it with flour.\\n9. Once the dough is rolled out, you can cut it into your desired pasta shape. For example, you can make fettuccine by cutting the dough into long, thin strips or make farfalle by cutting small rectangles and pinching them in the center.\\n10. As you cut the pasta, lay it out on a clean surface or hang it on a pasta drying rack to prevent sticking.\\n11. Repeat the rolling and cutting process with the remaining dough portions.\\n12. Once all the pasta is cut, bring a large pot of salted water to a boil. Cook the pasta for about 2-3 minutes or until al dente, which means it should still have a slight bite to it.\\n13. Drain the pasta and serve it with your favorite sauce or toppings.\\n\\nEnjoy your homemade Italian pasta!\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"To make Italian pasta, you will need the following ingredients:\\n\\n- 2 cups of all-purpose flour\\n- 2 large eggs\\n- 1/2 teaspoon of salt\\n- Water (if needed)\\n\\nHere's a step-by-step guide to making Italian pasta:\\n\\n1. On a clean surface or in a large mixing bowl, pour the flour and create a well in the center.\\n2. Crack the eggs into the well and add the salt.\\n3. Using a fork, beat the eggs and gradually incorporate the flour from the sides of the well. Continue mixing until a dough starts to form.\\n4. Once the dough becomes too stiff to mix with a fork, use your hands to knead it. Fold the dough over itself and press it down with the heel of your hand. Rotate the dough and repeat the process for about 10 minutes until the dough is smooth and elastic.\\n5. If the dough is too dry, add a little water, one tablespoon at a time, until it reaches the desired consistency. If the dough is too sticky, add a little flour.\\n6. Once the dough is ready, cover it with a clean kitchen towel or plastic wrap and let it rest for at least 30 minutes. This allows the gluten to relax and makes the dough easier to roll out.\\n7. After resting, divide the dough into smaller portions. Take one portion and flatten it with your hands.\\n8. Using a rolling pin, roll out the dough into a thin sheet. If the dough sticks to the surface or rolling pin, lightly dust it with flour.\\n9. Once the dough is rolled out, you can cut it into your desired pasta shape. For example, you can make fettuccine by cutting the dough into long, thin strips or make farfalle by cutting small rectangles and pinching them in the center.\\n10. As you cut the pasta, lay it out on a clean surface or hang it on a pasta drying rack to prevent sticking.\\n11. Repeat the rolling and cutting process with the remaining dough portions.\\n12. Once all the pasta is cut, bring a large pot of salted water to a boil. Cook the pasta for about 2-3 minutes or until al dente, which means it should still have a slight bite to it.\\n13. Drain the pasta and serve it with your favorite sauce or toppings.\\n\\nEnjoy your homemade Italian pasta!\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 13,\n",
      "      \"completion_tokens\": 483,\n",
      "      \"total_tokens\": 496\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"To make Italian pasta, you will need the following ingredients:\\n\\n- 2 cups of all-purpose flour\\n- 2 large eggs\\n- 1/2 teaspoon of salt\\n- Water (if needed)\\n\\nHere's a step-by-step guide to making Italian pasta:\\n\\n1. On a clean surface or in a large mixing bowl, pour the flour and create a well in the center.\\n2. Crack the eggs into the well and add the salt.\\n3. Using a fork, beat the eggs and gradually incorporate the flour from the sides of the well. Continue mixing until a dough starts to form.\\n4. Once the dough becomes too stiff to mix with a fork, use your hands to knead it. Fold the dough over itself and press it down with the heel of your hand. Rotate the dough and repeat the process for about 10 minutes until the dough is smooth and elastic.\\n5. If the dough is too dry, add a little water, one tablespoon at a time, until it reaches the desired consistency. If the dough is too sticky, add a little flour.\\n6. Once the dough is ready, cover it with a clean kitchen towel or plastic wrap and let it rest for at least 30 minutes. This allows the gluten to relax and makes the dough easier to roll out.\\n7. After resting, divide the dough into smaller portions. Take one portion and flatten it with your hands.\\n8. Using a rolling pin, roll out the dough into a thin sheet. If the dough sticks to the surface or rolling pin, lightly dust it with flour.\\n9. Once the dough is rolled out, you can cut it into your desired pasta shape. For example, you can make fettuccine by cutting the dough into long, thin strips or make farfalle by cutting small rectangles and pinching them in the center.\\n10. As you cut the pasta, lay it out on a clean surface or hang it on a pasta drying rack to prevent sticking.\\n11. Repeat the rolling and cutting process with the remaining dough portions.\\n12. Once all the pasta is cut, bring a large pot of salted water to a boil. Cook the pasta for about 2-3 minutes or until al dente, which means it should still have a slight bite to it.\\n13. Drain the pasta and serve it with your favorite sauce or toppings.\\n\\nEnjoy your homemade Italian pasta!\""
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.globals import set_llm_cache, set_debug\n",
    "from langchain.cache import InMemoryCache, SQLiteCache\n",
    "\n",
    "set_llm_cache(SQLiteCache(\"cache.db\"))\n",
    "set_debug(True) #작업코드를 볼 수 있음\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "chat.predict(\"How do you make italian pasta\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: How do you make italian pasta\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:llm:ChatOpenAI] [2ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"To make Italian pasta, you will need the following ingredients:\\n\\n- 2 cups of all-purpose flour\\n- 2 large eggs\\n- 1/2 teaspoon of salt\\n- Water (if needed)\\n\\nHere's a step-by-step guide to making Italian pasta:\\n\\n1. On a clean surface or in a large mixing bowl, pour the flour and create a well in the center.\\n2. Crack the eggs into the well and add the salt.\\n3. Using a fork, beat the eggs and gradually incorporate the flour from the sides of the well. Continue mixing until a dough starts to form.\\n4. Once the dough becomes too stiff to mix with a fork, use your hands to knead it. Fold the dough over itself and press it down with the heel of your hand. Rotate the dough and repeat the process for about 10 minutes until the dough is smooth and elastic.\\n5. If the dough is too dry, add a little water, one tablespoon at a time, until it reaches the desired consistency. If the dough is too sticky, add a little flour.\\n6. Once the dough is ready, cover it with a clean kitchen towel or plastic wrap and let it rest for at least 30 minutes. This allows the gluten to relax and makes the dough easier to roll out.\\n7. After resting, divide the dough into smaller portions. Take one portion and flatten it with your hands.\\n8. Using a rolling pin, roll out the dough into a thin sheet. If the dough sticks to the surface or rolling pin, lightly dust it with flour.\\n9. Once the dough is rolled out, you can cut it into your desired pasta shape. For example, you can make fettuccine by cutting the dough into long, thin strips or make farfalle by cutting small rectangles and pinching them in the center.\\n10. As you cut the pasta, lay it out on a clean surface or hang it on a pasta drying rack to prevent sticking.\\n11. Repeat the rolling and cutting process with the remaining dough portions.\\n12. Once all the pasta is cut, bring a large pot of salted water to a boil. Cook the pasta for about 2-3 minutes or until al dente, which means it should still have a slight bite to it.\\n13. Drain the pasta and serve it with your favorite sauce or toppings.\\n\\nEnjoy your homemade Italian pasta!\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"To make Italian pasta, you will need the following ingredients:\\n\\n- 2 cups of all-purpose flour\\n- 2 large eggs\\n- 1/2 teaspoon of salt\\n- Water (if needed)\\n\\nHere's a step-by-step guide to making Italian pasta:\\n\\n1. On a clean surface or in a large mixing bowl, pour the flour and create a well in the center.\\n2. Crack the eggs into the well and add the salt.\\n3. Using a fork, beat the eggs and gradually incorporate the flour from the sides of the well. Continue mixing until a dough starts to form.\\n4. Once the dough becomes too stiff to mix with a fork, use your hands to knead it. Fold the dough over itself and press it down with the heel of your hand. Rotate the dough and repeat the process for about 10 minutes until the dough is smooth and elastic.\\n5. If the dough is too dry, add a little water, one tablespoon at a time, until it reaches the desired consistency. If the dough is too sticky, add a little flour.\\n6. Once the dough is ready, cover it with a clean kitchen towel or plastic wrap and let it rest for at least 30 minutes. This allows the gluten to relax and makes the dough easier to roll out.\\n7. After resting, divide the dough into smaller portions. Take one portion and flatten it with your hands.\\n8. Using a rolling pin, roll out the dough into a thin sheet. If the dough sticks to the surface or rolling pin, lightly dust it with flour.\\n9. Once the dough is rolled out, you can cut it into your desired pasta shape. For example, you can make fettuccine by cutting the dough into long, thin strips or make farfalle by cutting small rectangles and pinching them in the center.\\n10. As you cut the pasta, lay it out on a clean surface or hang it on a pasta drying rack to prevent sticking.\\n11. Repeat the rolling and cutting process with the remaining dough portions.\\n12. Once all the pasta is cut, bring a large pot of salted water to a boil. Cook the pasta for about 2-3 minutes or until al dente, which means it should still have a slight bite to it.\\n13. Drain the pasta and serve it with your favorite sauce or toppings.\\n\\nEnjoy your homemade Italian pasta!\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"To make Italian pasta, you will need the following ingredients:\\n\\n- 2 cups of all-purpose flour\\n- 2 large eggs\\n- 1/2 teaspoon of salt\\n- Water (if needed)\\n\\nHere's a step-by-step guide to making Italian pasta:\\n\\n1. On a clean surface or in a large mixing bowl, pour the flour and create a well in the center.\\n2. Crack the eggs into the well and add the salt.\\n3. Using a fork, beat the eggs and gradually incorporate the flour from the sides of the well. Continue mixing until a dough starts to form.\\n4. Once the dough becomes too stiff to mix with a fork, use your hands to knead it. Fold the dough over itself and press it down with the heel of your hand. Rotate the dough and repeat the process for about 10 minutes until the dough is smooth and elastic.\\n5. If the dough is too dry, add a little water, one tablespoon at a time, until it reaches the desired consistency. If the dough is too sticky, add a little flour.\\n6. Once the dough is ready, cover it with a clean kitchen towel or plastic wrap and let it rest for at least 30 minutes. This allows the gluten to relax and makes the dough easier to roll out.\\n7. After resting, divide the dough into smaller portions. Take one portion and flatten it with your hands.\\n8. Using a rolling pin, roll out the dough into a thin sheet. If the dough sticks to the surface or rolling pin, lightly dust it with flour.\\n9. Once the dough is rolled out, you can cut it into your desired pasta shape. For example, you can make fettuccine by cutting the dough into long, thin strips or make farfalle by cutting small rectangles and pinching them in the center.\\n10. As you cut the pasta, lay it out on a clean surface or hang it on a pasta drying rack to prevent sticking.\\n11. Repeat the rolling and cutting process with the remaining dough portions.\\n12. Once all the pasta is cut, bring a large pot of salted water to a boil. Cook the pasta for about 2-3 minutes or until al dente, which means it should still have a slight bite to it.\\n13. Drain the pasta and serve it with your favorite sauce or toppings.\\n\\nEnjoy your homemade Italian pasta!\""
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.predict(\"How do you make italian pasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 비용계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 320\n",
      "\tPrompt Tokens: 14\n",
      "\tCompletion Tokens: 306\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.000633\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "with get_openai_callback() as usage:\n",
    "    chat.predict(\"What is the recipe for soju\")\n",
    "    print(usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "소주를 만드는 레시피는 다음과 같습니다:\n",
      "\n",
      "재료:\n",
      "- 1kg의 쌀\n",
      "- 1kg의 물\n",
      "- 1g의 산미를 위한 산화효모\n",
      "\n",
      "1. 쌀을 깨끗하게 씻어 물기를 제거합니다.\n",
      "2. 쌀을 냄비에 넣고 물을 부어 끓입니다.\n",
      "3. 끓는 물에 쌀을 30분 정도 삶아줍니다.\n",
      "4. 삶은 쌀을 체에 걸러 물기를 제거합니다.\n",
      "5. 체에 걸러낸 쌀을 그릇에 넣고 식힙니다.\n",
      "6. 식힌 쌀에 산화효모를 첨가하여 잘 섞어줍니다.\n",
      "7. 그릇을 뚜껑으로 덮고 어두운 곳에 2주 정도 숙성시킵니다.\n",
      "8. 숙성이 완료되면 체에 걸러내어 깨끗한 병에 담습니다.\n",
      "9. 소주를 냉장고에 보관하고 차가운 상태에서 마시면 맛있습니다.\n",
      "\n",
      "이렇게 만든 소주는 숙성 기간에 따라 알코올 도수와 맛이 달라질 수 있으니, 자신의 취향에 맞게 숙성 기간을 조절해주세요. 또한, 소주를 마시기 전에는 적절한 양의 물과 함께 섭취하는 것이 좋습니다. 식빵을 만드는 레시피는 다음과 같습니다:\n",
      "\n",
      "재료:\n",
      "- 밀가루 500g\n",
      "- 설탕 50g\n",
      "- 소금 10g\n",
      "- 버터 50g\n",
      "- 물 300ml\n",
      "- 효모 10g\n",
      "- 계란 1개\n",
      "- 우유 100ml\n",
      "\n",
      "1. 밀가루, 설탕, 소금을 큰 그릇에 섞어줍니다.\n",
      "2. 버터를 작은 조각으로 잘라서 밀가루에 넣고 손으로 버터를 밀가루에 반죽하듯이 섞어줍니다.\n",
      "3. 물을 조금씩 넣어가며 반죽을 만들어줍니다. 반죽이 부드럽고 탄력있게 섞이도록 합니다.\n",
      "4. 효모를 따뜻한 물에 녹여줍니다. 약간의 설탕을 넣어 효모가 잘 발효되도록 합니다.\n",
      "5. 효모를 넣은 반죽에 우유와 계란을 넣고 섞어줍니다.\n",
      "6. 반죽을 덮어서 따뜻한 곳에서 약 1시간 동안 발효시켜줍니다. 반죽이 약간 부풀어오르고 부드러워질 것입니다.\n",
      "7. 발효된 반죽을 다시 잘 섞어줍니다.\n",
      "8. 반죽을 미니 식빵 틀에 넣고 가득 채워줍니다.\n",
      "9. 식빵 틀을 미리 기름칠한 베이킹 팬에 올려줍니다.\n",
      "10. 180도로 예열된 오븐에서 약 20-25분 동안 굽습니다. 식빵이 골드 브라운으로 구워질 때까지 굽습니다.\n",
      "11. 오븐에서 꺼내서 식힌 후에 식빵을 꺼내줍니다.\n",
      "\n",
      "이제 식빵이 완성되었습니다! 맛있게 즐기세요. \n",
      "\n",
      "Tokens Used: 1096\n",
      "\tPrompt Tokens: 60\n",
      "\tCompletion Tokens: 1036\n",
      "Successful Requests: 2\n",
      "Total Cost (USD): $0.0021620000000000003\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as usage:\n",
    "    a = chat.predict(\"소주를 만드는 레시피는 무엇인가요?\")\n",
    "    b = chat.predict(\"식빵을 만드는 레시피는 무엇인가요?\")\n",
    "    print(a, b, \"\\n\")\n",
    "    print(usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms.openai import OpenAI\n",
    "from langchain.llms.loading import load_llm\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "\n",
    "chat = OpenAI(\n",
    "    temperature=0.1,\n",
    "    max_tokens=450,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat.save(\"model.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mOpenAI\u001b[0m\n",
      "Params: {'model_name': 'text-davinci-003', 'temperature': 0.1, 'max_tokens': 450, 'top_p': 1.0, 'frequency_penalty': 0.0, 'presence_penalty': 0.0, 'n': 1, 'request_timeout': None, 'logit_bias': {}}\n"
     ]
    }
   ],
   "source": [
    "chat = load_llm(\"./model.json\")\n",
    "\n",
    "print(chat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory\n",
    "- ConversationBufferMemory : 단순히 이전 대화 내용 전체를 저장하는 메모리. text completion이나 대화 예측, 자동완성같은거 사용할때 유용함\n",
    "- ConversationBufferWindowMemory : 대화의 특정 부분만 저장하는 메모리. 가장 최신의 것만 저장함.저장범위는 사용자가 지정함.저장범위를 초과하면 과거데이터부터 지움\n",
    "- conversationSummaryMemory: llm을 사용해서 대화 요약하여 저장함\n",
    "- ConversationSummaryBufferMemory : 메모리에 보내온 메시지의 수를 지정하고 지정범위를 초과하면 과거 대화는 요약하여 저장함\n",
    "- ConversationKGMemory : 대화중에 엔티티의 knowlege graph를 만든다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='Hi'), AIMessage(content='How are you?')]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "memory.save_context({\"input\":\"Hi\"},{\"output\":\"How are you?\"})\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(\n",
    "    return_messages=True,\n",
    "    k=4\n",
    ")\n",
    "\n",
    "\n",
    "def add_message(input, output):\n",
    "    memory.save_context({\"input\":input},{\"output\":output})\n",
    "\n",
    "add_message(1,1)\n",
    "add_message(2,2)\n",
    "add_message(3,3)\n",
    "add_message(4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='1'),\n",
       "  AIMessage(content='1'),\n",
       "  HumanMessage(content='2'),\n",
       "  AIMessage(content='2'),\n",
       "  HumanMessage(content='3'),\n",
       "  AIMessage(content='3'),\n",
       "  HumanMessage(content='4'),\n",
       "  AIMessage(content='4')]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(5,5)\n",
    "add_message(6,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='3'),\n",
       "  AIMessage(content='3'),\n",
       "  HumanMessage(content='4'),\n",
       "  AIMessage(content='4'),\n",
       "  HumanMessage(content='5'),\n",
       "  AIMessage(content='5'),\n",
       "  HumanMessage(content='6'),\n",
       "  AIMessage(content='6')]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryMemory(llm=llm)\n",
    "\n",
    "def add_message(input, output):\n",
    "    memory.save_context({\"input\":input},{\"output\":output})\n",
    "\n",
    "def get_history():\n",
    "    return memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(\"Hi. I'm Nicolas. I live in South Korea\",\"Wow that is so cool\")\n",
    "\n",
    "add_message(\"South Korea is so pretty\", \"I wish I could go!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'The human introduces themselves as Nicolas and mentions that they live in South Korea. The AI responds by expressing admiration for this information and expressing a desire to visit South Korea because it is so pretty.'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=150,\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "def add_message(input, output):\n",
    "    memory.save_context({\"input\":input},{\"output\":output})\n",
    "\n",
    "def get_history():\n",
    "    return memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(\"안녕. 내이름은 보라야. 나는 동탄에 살아\",\"오 멋진뎅\")\n",
    "add_message(\"한국은 아주 멋진 곳이야\",\"나도 가보고싶다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content='The human greets the AI in Korean and introduces themselves as Bora, mentioning that they live in Dongtan.'),\n",
       "  AIMessage(content='오 멋진뎅'),\n",
       "  HumanMessage(content='안녕. 내이름은 보라야. 나는 동탄에 살아'),\n",
       "  AIMessage(content='오 멋진뎅'),\n",
       "  HumanMessage(content='한국은 아주 멋진 곳이야'),\n",
       "  AIMessage(content='나도 가보고싶다'),\n",
       "  HumanMessage(content='넌 한국에 한번도 와본적 없니?'),\n",
       "  AIMessage(content='한번 가본적 있는데 어릴때라 기억이 안나')]}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(\"넌 한국에 한번도 와본적 없니?\",\"한번 가본적 있는데 어릴때라 기억이 안나\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(\"내가 가장 좋아하는 음식은 빵이야\",\"빵은 정말 맛있지 인정\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content='The human greets the AI in Korean and introduces themselves as Bora, mentioning that they live in Dongtan. The AI responds with \"Oh, how cool.\" The human then says \"Hello. My name is Bora. I live in Dongtan.\"'),\n",
       "  AIMessage(content='오 멋진뎅'),\n",
       "  HumanMessage(content='한국은 아주 멋진 곳이야'),\n",
       "  AIMessage(content='나도 가보고싶다'),\n",
       "  HumanMessage(content='넌 한국에 한번도 와본적 없니?'),\n",
       "  AIMessage(content='한번 가본적 있는데 어릴때라 기억이 안나'),\n",
       "  HumanMessage(content='내가 가장 좋아하는 음식은 빵이야'),\n",
       "  AIMessage(content='빵은 정말 맛있지 인정')]}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(\"내가 가장 좋아하는 빵집 이름은 풀브렛첼이야\",\"와 거기 인스타그램 계정이 뭐니?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content='The human greets the AI in Korean and introduces themselves as Bora, mentioning that they live in Dongtan. The AI responds with \"Oh, how cool.\" The human then says \"Hello. My name is Bora. I live in Dongtan.\" The AI replies with \"Oh, how cool\" in Korean. The human then says \"Korea is a very cool place.\" The AI responds with \"I want to visit too.\"'),\n",
       "  HumanMessage(content='넌 한국에 한번도 와본적 없니?'),\n",
       "  AIMessage(content='한번 가본적 있는데 어릴때라 기억이 안나'),\n",
       "  HumanMessage(content='내가 가장 좋아하는 음식은 빵이야'),\n",
       "  AIMessage(content='빵은 정말 맛있지 인정'),\n",
       "  HumanMessage(content='내가 가장 좋아하는 빵집 이름은 풀브렛첼이야'),\n",
       "  AIMessage(content='와 거기 인스타그램 계정이 뭐니?')]}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationKGMemory\n",
    "\n",
    "memory = ConversationKGMemory(\n",
    "    llm=llm,\n",
    "    return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_message(input, output):\n",
    "    memory.save_context({\"input\":input},{\"output\":output})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(\"Hi. I'm Bora. I live in Dongtan\",\"Wow That is so cool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content='On Bora: Bora is a person. Bora lives in Dongtan.')]}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({\"input\":\"Who is Bora?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(\"Bora likes Bread\",\"Wow that is so cool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content='On Bora: Bora is a person. Bora lives in Dongtan. Bora likes Bread.')]}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({\"inputs\":\"What does bora like?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Model에 Memory 넣기 = LLM Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are a helpful AI talking to a humam.\n",
      "\n",
      "[]\n",
      "\n",
      "Human:My name is Bora\n",
      "You:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello Bora! How can I assist you today?'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=120,\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "template = \"\"\"\n",
    "You are a helpful AI talking to a humam.\n",
    "\n",
    "{chat_history}\n",
    "\n",
    "Human:{question}\n",
    "You:\n",
    "\"\"\"\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    prompt=PromptTemplate.from_template(template),\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "chain.predict(question=\"My name is Bora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are a helpful AI talking to a humam.\n",
      "\n",
      "Human: My name is Bora\n",
      "AI: Hello Bora! How can I assist you today?\n",
      "\n",
      "Human:I live in Dongtan\n",
      "You:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"That's great, Bora! Dongtan is a city located in South Korea. How can I assist you with anything related to Dongtan?\""
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"I live in Dongtan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are a helpful AI talking to a humam.\n",
      "\n",
      "Human: My name is Bora\n",
      "AI: Hello Bora! How can I assist you today?\n",
      "Human: I live in Dongtan\n",
      "AI: That's great, Bora! Dongtan is a city located in South Korea. How can I assist you with anything related to Dongtan?\n",
      "\n",
      "Human:What is my name?\n",
      "You:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is Bora.'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': \"Human: My name is Bora\\nAI: Hello Bora! How can I assist you today?\\nHuman: I live in Dongtan\\nAI: That's great, Bora! Dongtan is a city located in South Korea. How can I assist you with anything related to Dongtan?\\nHuman: What is my name?\\nAI: Your name is Bora.\"}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=120,\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "prompts = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"You are a helpful AI talking to a human\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\",\"{question}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    prompt=prompts,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a helpful AI talking to a human\n",
      "Human: My name is bora\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello Bora! How can I assist you today?'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"My name is bora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a helpful AI talking to a human\n",
      "Human: My name is bora\n",
      "AI: Hello Bora! How can I assist you today?\n",
      "Human: I live in Dongtan\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"That's great, Bora! Dongtan is a city located in South Korea, known for its modern infrastructure and eco-friendly initiatives. How can I help you with anything related to Dongtan or any other topic?\""
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"I live in Dongtan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a helpful AI talking to a human\n",
      "Human: My name is bora\n",
      "AI: Hello Bora! How can I assist you today?\n",
      "Human: I live in Dongtan\n",
      "AI: That's great, Bora! Dongtan is a city located in South Korea, known for its modern infrastructure and eco-friendly initiatives. How can I help you with anything related to Dongtan or any other topic?\n",
      "Human: What is my name?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is Bora.'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question = \"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='My name is bora'),\n",
       " AIMessage(content='Hello Bora! How can I assist you today?'),\n",
       " HumanMessage(content='I live in Dongtan'),\n",
       " AIMessage(content=\"That's great, Bora! Dongtan is a city located in South Korea, known for its modern infrastructure and eco-friendly initiatives. How can I help you with anything related to Dongtan or any other topic?\"),\n",
       " HumanMessage(content='What is my name?'),\n",
       " AIMessage(content='Your name is Bora.')]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})[\"chat_history\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LCEL 방식의 memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=120,\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\",\"You are helpful AI talking to a human\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\",\"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def load_memory(_):\n",
    "    return memory.load_memory_variables({})[\"history\"]\n",
    "\n",
    "chain = RunnablePassthrough.assign(history=load_memory) | prompt | llm\n",
    "\n",
    "def invoke_chain(question):\n",
    "    result = chain.invoke({\"question\": question})\n",
    "    memory.save_context(\n",
    "        {\"input\": question},\n",
    "        {\"output\": result.content},\n",
    "    )\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"That's a lovely name for a dog! Dalra is a unique and charming name. How can I assist you with Dalra today?\"\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"My dog's name is Dalra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='My name is bora'),\n",
       " AIMessage(content='Hello Bora! How can I assist you today?'),\n",
       " HumanMessage(content='What is my name?'),\n",
       " AIMessage(content='Your name is Bora.'),\n",
       " HumanMessage(content=\"My dog's name is Dalra\"),\n",
       " AIMessage(content=\"That's a lovely name for a dog! Dalra is a unique and charming name. How can I assist you with Dalra today?\")]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})[\"history\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Your name is Bora.'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='안녕하세요, 윤보라님! 어떻게 도와드릴까요?'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"내 이름은 윤보라 입니다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='당신의 이름은 윤보라입니다.'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"내 이름이 뭐야?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='알겠습니다. 우리집 강아지의 이름은 달라입니다. 어떤 도움이 필요하신가요?'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"우리집 강아지 이름은 달라야\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='물론이죠! 제가 도와드릴게요. 제 이름은 AI 보라이고, 저는 유저님의 이름이 Bora이고 강아지의 이름이 Dala인 것을 알고 있습니다. 맞나요?'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"내 이름과 내가 키우는 강아지 이름을 맞춰봐\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='네, 유저님의 이름은 보라이고, 강아지의 이름은 달라입니다. 맞나요?'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"내 이름이랑 강아지 이름을 한글로 대답해줘\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content=\"The human introduces themselves as Bora and asks the AI for its name. The AI responds that its name is Bora. Bora then introduces themselves in Korean, and the AI responds in Korean, greeting them and asking how it can help. Bora asks what their name is in Korean, and the AI responds that their name is Yoon Bora. Bora mentions that their dog's name should be different, and the AI acknowledges this and says that their dog's name is Dala. The AI then asks how it can assist Bora. Bora asks the AI to match their name and their dog's name. The AI agrees to help and says its name is AI Bora, and it knows that Bora's name is Bora and their dog's name is Dala.\"),\n",
       "  HumanMessage(content='내 이름이랑 강아지 이름을 한글로 대답해줘'),\n",
       "  AIMessage(content='네, 유저님의 이름은 보라이고, 강아지의 이름은 달라입니다. 맞나요?')]}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import TextLoader, PyPDFLoader\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "\n",
    "splitter = CharacterTextSplitter.from_tiktoken_encoder(separator=\"\\n\",\n",
    "    chunk_size=600, chunk_overlap=100,\n",
    "    )\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "loader = UnstructuredFileLoader(\"./files/chapter_one.pdf\")\n",
    "\n",
    "loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1536\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "embedder = OpenAIEmbeddings()\n",
    "vector = embedder.embed_query(\"Hi\")\n",
    "len(vector)\n",
    "\n",
    "vector = embedder.embed_documents([\"hi\",'how','are','you'])\n",
    "print(len(vector),len(vector[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "from langchain.storage import LocalFileStore\n",
    "\n",
    "cache_dir = LocalFileStore(\"./.cache/\")\n",
    "\n",
    "\n",
    "loader = UnstructuredFileLoader(\"./files/chapter_one.docx\")\n",
    "docs = loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "embedder = OpenAIEmbeddings()\n",
    "\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(\n",
    "    embedder, cache_dir\n",
    ")\n",
    "\n",
    "vectorstore = Chroma.from_documents(docs, cached_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"The Ministry of Love was the really frightening one. There were no windows in it at all. Winston had never been inside the Ministry of Love, nor within half a kilometre of it. It was a place impossible to enter except on official business, and then only by penetrating through a maze of barbed-wire entanglements, steel doors, and hidden machine-gun nests. Even the streets leading up to its outer barriers were roamed by gorilla-faced guards in black uniforms, armed with jointed truncheons.\\nWinston turned round abruptly. He had set his features into the expression of quiet optimism which it was advisable to wear when facing the telescreen. He crossed the room into the tiny kitchen. By leaving the Ministry at this time of day he had sacrificed his lunch in the canteen, and he was aware that there was no food in the kitchen except a hunk of dark-coloured bread which had got to be saved for tomorrow's breakfast. He took down from the shelf a bottle of colourless liquid with a plain white label marked VICTORY GIN. It gave off a sickly, oily smell, as of Chinese ricespirit. Winston poured out nearly a teacupful, nerved himself for a shock, and gulped it down like a dose of medicine.\\nInstantly his face turned scarlet and the water ran out of his eyes. The stuff was like nitric acid, and moreover, in swallowing it one had the sensation of being hit on the back of the head with a rubber club. The next moment, however, the burning in his belly died down and the world began to look more cheerful. He took a cigarette from a crumpled packet marked VICTORY CIGARETTES and incautiously held it upright, whereupon the tobacco fell out on to the floor. With the next he was more successful. He went back to the living-room and sat down at a small table that stood to the left of the telescreen. From the table drawer he took out a penholder, a bottle of ink, and a thick, quarto-sized blank book with a red back and a marbled cover.\", metadata={'source': './files/chapter_one.docx'}),\n",
       " Document(page_content=\"The Ministry of Love was the really frightening one. There were no windows in it at all. Winston had never been inside the Ministry of Love, nor within half a kilometre of it. It was a place impossible to enter except on official business, and then only by penetrating through a maze of barbed-wire entanglements, steel doors, and hidden machine-gun nests. Even the streets leading up to its outer barriers were roamed by gorilla-faced guards in black uniforms, armed with jointed truncheons.\\nWinston turned round abruptly. He had set his features into the expression of quiet optimism which it was advisable to wear when facing the telescreen. He crossed the room into the tiny kitchen. By leaving the Ministry at this time of day he had sacrificed his lunch in the canteen, and he was aware that there was no food in the kitchen except a hunk of dark-coloured bread which had got to be saved for tomorrow's breakfast. He took down from the shelf a bottle of colourless liquid with a plain white label marked VICTORY GIN. It gave off a sickly, oily smell, as of Chinese ricespirit. Winston poured out nearly a teacupful, nerved himself for a shock, and gulped it down like a dose of medicine.\\nInstantly his face turned scarlet and the water ran out of his eyes. The stuff was like nitric acid, and moreover, in swallowing it one had the sensation of being hit on the back of the head with a rubber club. The next moment, however, the burning in his belly died down and the world began to look more cheerful. He took a cigarette from a crumpled packet marked VICTORY CIGARETTES and incautiously held it upright, whereupon the tobacco fell out on to the floor. With the next he was more successful. He went back to the living-room and sat down at a small table that stood to the left of the telescreen. From the table drawer he took out a penholder, a bottle of ink, and a thick, quarto-sized blank book with a red back and a marbled cover.\", metadata={'source': './files/chapter_one.docx'}),\n",
       " Document(page_content=\"The Ministry of Love was the really frightening one. There were no windows in it at all. Winston had never been inside the Ministry of Love, nor within half a kilometre of it. It was a place impossible to enter except on official business, and then only by penetrating through a maze of barbed-wire entanglements, steel doors, and hidden machine-gun nests. Even the streets leading up to its outer barriers were roamed by gorilla-faced guards in black uniforms, armed with jointed truncheons.\\nWinston turned round abruptly. He had set his features into the expression of quiet optimism which it was advisable to wear when facing the telescreen. He crossed the room into the tiny kitchen. By leaving the Ministry at this time of day he had sacrificed his lunch in the canteen, and he was aware that there was no food in the kitchen except a hunk of dark-coloured bread which had got to be saved for tomorrow's breakfast. He took down from the shelf a bottle of colourless liquid with a plain white label marked VICTORY GIN. It gave off a sickly, oily smell, as of Chinese ricespirit. Winston poured out nearly a teacupful, nerved himself for a shock, and gulped it down like a dose of medicine.\\nInstantly his face turned scarlet and the water ran out of his eyes. The stuff was like nitric acid, and moreover, in swallowing it one had the sensation of being hit on the back of the head with a rubber club. The next moment, however, the burning in his belly died down and the world began to look more cheerful. He took a cigarette from a crumpled packet marked VICTORY CIGARETTES and incautiously held it upright, whereupon the tobacco fell out on to the floor. With the next he was more successful. He went back to the living-room and sat down at a small table that stood to the left of the telescreen. From the table drawer he took out a penholder, a bottle of ink, and a thick, quarto-sized blank book with a red back and a marbled cover.\", metadata={'source': './files/chapter_one.docx'}),\n",
       " Document(page_content=\"The Ministry of Love was the really frightening one. There were no windows in it at all. Winston had never been inside the Ministry of Love, nor within half a kilometre of it. It was a place impossible to enter except on official business, and then only by penetrating through a maze of barbed-wire entanglements, steel doors, and hidden machine-gun nests. Even the streets leading up to its outer barriers were roamed by gorilla-faced guards in black uniforms, armed with jointed truncheons.\\nWinston turned round abruptly. He had set his features into the expression of quiet optimism which it was advisable to wear when facing the telescreen. He crossed the room into the tiny kitchen. By leaving the Ministry at this time of day he had sacrificed his lunch in the canteen, and he was aware that there was no food in the kitchen except a hunk of dark-coloured bread which had got to be saved for tomorrow's breakfast. He took down from the shelf a bottle of colourless liquid with a plain white label marked VICTORY GIN. It gave off a sickly, oily smell, as of Chinese ricespirit. Winston poured out nearly a teacupful, nerved himself for a shock, and gulped it down like a dose of medicine.\\nInstantly his face turned scarlet and the water ran out of his eyes. The stuff was like nitric acid, and moreover, in swallowing it one had the sensation of being hit on the back of the head with a rubber club. The next moment, however, the burning in his belly died down and the world began to look more cheerful. He took a cigarette from a crumpled packet marked VICTORY CIGARETTES and incautiously held it upright, whereupon the tobacco fell out on to the floor. With the next he was more successful. He went back to the living-room and sat down at a small table that stood to the left of the telescreen. From the table drawer he took out a penholder, a bottle of ink, and a thick, quarto-sized blank book with a red back and a marbled cover.\", metadata={'source': './files/chapter_one.docx'})]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = vectorstore.similarity_search(\"where does winston live\")\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/borabbo/Desktop/GPT/env/lib/python3.11/site-packages/langchain/chains/llm.py:349: UserWarning: The apply_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Victory Mansions is a building with glass doors and a hallway that smells of boiled cabbage and old rag mats. On one wall of the hallway, there is a large colored poster depicting the face of a man in his forties with a black mustache. The building has stairs because the lift is usually not working, and the flat that Winston Smith lives in is on the seventh floor. Inside the flat, there is a telescreen, an oblong metal plaque that functions as a dulled mirror and broadcasts a voice reading out figures related to pig-iron production. Winston is described as a small and frail figure, wearing blue overalls, with fair hair and a naturally sanguine face. The skin on his face is roughened from the use of coarse soap and blunt razor blades, as well as the cold weather. '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "cache_dir = LocalFileStore(\"./.cache/\")\n",
    "\n",
    "splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size = 600,\n",
    "    chunk_overlap = 100,\n",
    ")\n",
    "\n",
    "loader = UnstructuredFileLoader(\"./files/chapter_one.docx\")\n",
    "\n",
    "docs = loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(\n",
    "    embeddings, cache_dir\n",
    ")\n",
    "\n",
    "vectorstor = FAISS.from_documents(docs, cached_embeddings)\n",
    "\n",
    "chain = RetrievalQA.from_chain_type(\n",
    "    llm = llm,\n",
    "    chain_type='map_rerank', #'stuff', 'map_reduce', 'refine', 'map_rerank'\n",
    "    retriever = vectorstor.as_retriever(),\n",
    ")\n",
    "\n",
    "\n",
    "chain.run(\"Describe Victory Mansions\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LCLE로 구현하기 : stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Victory Mansions is a building where Winston Smith resides. It is described as having glass doors at the entrance, which allow gritty dust to enter along with people. The hallway of Victory Mansions has a smell of boiled cabbage and old rag mats. There is a large colored poster on one end of the hallway, depicting the face of a man in his forties with a black mustache. The building has seven floors, and the elevator is rarely working due to the electricity being cut off during daylight hours. The poster with the enormous face and the caption \"BIG BROTHER IS WATCHING YOU\" is displayed on each landing opposite the elevator shaft.')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "cache_dir = LocalFileStore(\"./.cache/\")\n",
    "\n",
    "splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size = 600,\n",
    "    chunk_overlap = 100,\n",
    ")\n",
    "\n",
    "loader = UnstructuredFileLoader(\"./files/chapter_one.docx\")\n",
    "docx = loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(embeddings, cache_dir)\n",
    "vectorstore = FAISS.from_documents(docx, cached_embeddings)\n",
    "retriver = vectorstore.as_retriever()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are a helpful assistant. Answer questions using only the following context. If you don't know \\\n",
    "        the answer just say you don't know, don't make it up: \\n\\n {context}\"),\n",
    "    (\"human\",\"{question}\")\n",
    "])\n",
    "\n",
    "chain = ({\"context\": retriver,\"question\": RunnablePassthrough()} | prompt | llm)\n",
    "\n",
    "chain.invoke(\"Describe Victory Mansions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Victory Mansions is a building where Winston Smith resides. It is described as having glass doors at the entrance, which allow gritty dust to enter along with people. The hallway of Victory Mansions has a smell of boiled cabbage and old rag mats. On one end of the hallway, there is a large colored poster depicting the face of a man in his forties with a black mustache. The building has seven floors, and the flat where Winston lives is on the seventh floor. The flat is accessed by stairs since the lift is rarely working. The building is not well-maintained, with rotting houses and patched windows. From the roof of Victory Mansions, one can see the other three buildings that house the Ministries of Truth, Peace, Love, and Plenty.')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "cache_dir = LocalFileStore(\"./.cache/\")\n",
    "\n",
    "splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "loader = UnstructuredFileLoader(\"./files/chapter_one.txt\")\n",
    "\n",
    "docs = loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(embeddings, cache_dir)\n",
    "\n",
    "vectorstore = FAISS.from_documents(docs, cached_embeddings)\n",
    "\n",
    "retriver = vectorstore.as_retriever()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer questions using only the following context. If you don't know the answer just say you don't know, don't make it up:\\n\\n{context}\",\n",
    "        ),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": retriver,\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    ")\n",
    "\n",
    "chain.invoke(\"Describe Victory Mansions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LCEL로 구현하기 : Map Reduce LCEL Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='윈스턴은 직장인으로서 진실부(미니트루)로 출근합니다.')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "cache_dir = LocalFileStore(\"./.cache/\")\n",
    "\n",
    "splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "\n",
    "loader = UnstructuredFileLoader(\"./files/chapter_one.docx\")\n",
    "\n",
    "docs = loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(\n",
    "    embeddings, cache_dir\n",
    ")\n",
    "\n",
    "vectorstore = FAISS.from_documents(docs, cached_embeddings)\n",
    "\n",
    "retriver = vectorstore.as_retriever()\n",
    "\n",
    "#list of docs : retriver를 통해 doc의 리스트를 받는다\n",
    "\n",
    "#for doc in list of docs | prompt | llm : 각각의 docs에 대해 질문에 대한 답을 받는다\n",
    "\n",
    "#for respone in list of llm respones | put them all together : LLM의 답들을 모두 합쳐서 (하나의 context로)\n",
    "\n",
    "#final_doc | prompt | llm :final 로 입력\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "map_doc_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"\"\"\n",
    "    다음의 긴 document의 일부 중, 질문에 대한 답변을 생성하는 것과 관련이 있는 부분을 찾아주세요.\n",
    "    관련이 있는 부분을 찾는다면, 해당 text를 그대로 반환해주세요.\n",
    "    --------\n",
    "    {portion}\n",
    "    \"\"\"),\n",
    "    (\"human\", \"{question}\"),\n",
    "])\n",
    "\n",
    "map_doc_chain = map_doc_prompt | llm\n",
    "\n",
    "\n",
    "\n",
    "#def map_docs(inputs):\n",
    "#    documents = inputs['documents']\n",
    "#    question = inputs['question']\n",
    "#    results = []\n",
    "#    for document in documents:\n",
    "#        result = map_doc_chain.invoke({\n",
    "#            \"portion\": document.page_content,\n",
    "#            \"question\":question\n",
    "#        }).content\n",
    "#        results.append(result)\n",
    "#    results = \"\\n\\n\".join(results)\n",
    "#    return results\n",
    "\n",
    "#더 깔끔하게 코드작성\n",
    "\n",
    "def map_docs(inputs):\n",
    "    documents = inputs['documents']\n",
    "    question = inputs['question']\n",
    "    return \"\\n\\n\".join(\n",
    "        map_doc_chain.invoke(\n",
    "            {\"portion\": doc.page_content,\"question\": question\n",
    "    }).content for doc in documents) #LLM의 AI 답에서 text만 추출하려면 .content / retriver의 documents 리스트에서 text만 추출하려면 .page_content\n",
    "\n",
    "# 여기에서 inputs은 map_chain애서 값을 받는다 : RunnableLambda(map_docs) 앞의 값을 전달받기 때문에 !\n",
    "# {\"ducments\": retriver(documents들의 리스트), \"question\": question}\n",
    "map_chain = {\"documents\": retriver, \"question\": RunnablePassthrough()} | RunnableLambda(map_docs)\n",
    "\n",
    "final_prompt =  ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "    \"\"\"\n",
    "    주어진 긴 document의 발췌문들과 question을 통해 최종 답변을 생성하세요.\n",
    "    답을 모른다면, 지어내지 말고 그냥 모른다고 하세요\n",
    "    ---------\n",
    "    {context}\n",
    "    \"\"\"),\n",
    "    (\"human\",\"{question}\")\n",
    "])\n",
    "\n",
    "\n",
    "chain = {\"context\":map_chain , \"question\": RunnablePassthrough()}| final_prompt | llm\n",
    "\n",
    "chain.invoke(\"윈스턴은 어디로 출근하나요?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hugging Face"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' A potato is a starchy, tuberous crop that is widely grown and consumed around the world. It is a root vegetable that is native to the Andes region of South America and was first domesticated by the indigenous peoples of that region thousands of years ago.\\n\\nPotatoes are a versatile ingredient and can be prepared in a variety of ways, including boiling, baking, frying, and roasting. They are a good source of carboh'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import HuggingFaceHub\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"[INST]What is the meaning of {word}?[\\INST]\")\n",
    "\n",
    "llm = HuggingFaceHub(\n",
    "    repo_id=\"mistralai/Mixtral-8x7B-Instruct-v0.1\", #\"mistralai/Mistral-7B-v0.1\",\n",
    "    model_kwargs={\n",
    "        \"max_new_token\":250,\n",
    "    },\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "chain.invoke({\n",
    "    \"word\":\"potato\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading config.json: 100%|██████████| 665/665 [00:00<00:00, 714kB/s]\n",
      "Downloading vocab.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 1.39MB/s]\n",
      "Downloading merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 10.5MB/s]\n",
      "Downloading tokenizer.json: 100%|██████████| 1.36M/1.36M [00:00<00:00, 1.75MB/s]\n",
      "Downloading model.safetensors: 100%|██████████| 548M/548M [00:45<00:00, 12.1MB/s] \n",
      "Downloading generation_config.json: 100%|██████████| 124/124 [00:00<00:00, 390kB/s]\n",
      "Using pad_token, but it is not set yet.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' potato. A potato has to be cooked to high temperature and then chopped. It is a potato that is high in fat and carbohydrates (more on these in step 6). A potato can be processed for food with only 2 components, fat, carbohydrates and'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"A {word} is a\")\n",
    "\n",
    "llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"gpt2\",\n",
    "    task=\"text-generation\",\n",
    "    pipeline_kwargs={\"max_new_tokens\":50},\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "chain.invoke({\"word\":\"potato\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "팥붕어빵 5개 드릴까요?\n",
      "슈크림붕어빵 7개 드릴까요?\n"
     ]
    }
   ],
   "source": [
    "class Make_boong:\n",
    "    def make_p(self, num1, num2):\n",
    "        if num1 == \"팥\":\n",
    "            print(f\"{num1}붕어빵 {num2}개 드릴까요?\")\n",
    "        elif num1 == \"슈크림\":\n",
    "            print(f\"{num1}붕어빵 {num2}개 드릴까요?\")\n",
    "\n",
    "\n",
    "my_boong = Make_boong()\n",
    "my_boong.make_p(\"팥\", 5)\n",
    "my_boong.make_p(\"슈크림\", 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Call : Json 스키마"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'name': 'create_quiz', 'arguments': '{\\n  \"questions\": [\\n    {\\n      \"question\": \"What is the capital city of South Korea?\",\\n      \"answers\": [\\n        {\"answer\": \"Busan\", \"correct\": false},\\n        {\"answer\": \"Seoul\", \"correct\": true},\\n        {\"answer\": \"Incheon\", \"correct\": false},\\n        {\"answer\": \"Daegu\", \"correct\": false},\\n        {\"answer\": \"Gwangju\", \"correct\": false}\\n      ]\\n    },\\n    {\\n      \"question\": \"Which river flows through Seoul?\",\\n      \"answers\": [\\n        {\"answer\": \"Han River\", \"correct\": true},\\n        {\"answer\": \"Nakdong River\", \"correct\": false},\\n        {\"answer\": \"Geum River\", \"correct\": false},\\n        {\"answer\": \"Yeongsan River\", \"correct\": false},\\n        {\"answer\": \"Taedong River\", \"correct\": false}\\n      ]\\n    },\\n    {\\n      \"question\": \"What is the tallest building in Seoul?\",\\n      \"answers\": [\\n        {\"answer\": \"Lotte World Tower\", \"correct\": true},\\n        {\"answer\": \"N Seoul Tower\", \"correct\": false},\\n        {\"answer\": \"63 Building\", \"correct\": false},\\n        {\"answer\": \"Seoul Sky\", \"correct\": false},\\n        {\"answer\": \"Mokdong Hyperion Tower\", \"correct\": false}\\n      ]\\n    },\\n    {\\n      \"question\": \"Which palace is located in the heart of Seoul?\",\\n      \"answers\": [\\n        {\"answer\": \"Gyeongbokgung Palace\", \"correct\": true},\\n        {\"answer\": \"Changdeokgung Palace\", \"correct\": false},\\n        {\"answer\": \"Deoksugung Palace\", \"correct\": false},\\n        {\"answer\": \"Changgyeonggung Palace\", \"correct\": false},\\n        {\"answer\": \"Gyeonghuigung Palace\", \"correct\": false}\\n      ]\\n    },\\n    {\\n      \"question\": \"What is the famous shopping district in Seoul?\",\\n      \"answers\": [\\n        {\"answer\": \"Myeongdong\", \"correct\": true},\\n        {\"answer\": \"Gangnam\", \"correct\": false},\\n        {\"answer\": \"Hongdae\", \"correct\": false},\\n        {\"answer\": \"Dongdaemun\", \"correct\": false},\\n        {\"answer\": \"Itaewon\", \"correct\": false}\\n      ]\\n    }\\n  ]\\n}'}})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "function = {\n",
    "    \"name\":\"create_quiz\",\n",
    "    \"description\": \"function that takes a list of questions and answers and returns a quiz\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"questions\":{\n",
    "                \"type\": \"array\",\n",
    "                \"items\":{\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\":{\n",
    "                        \"question\": {\n",
    "                            \"type\": \"string\"},\n",
    "                        \"answers\": {\n",
    "                            \"type\": \"array\",\n",
    "                            \"items\":{\n",
    "                                \"type\": \"object\",\n",
    "                                \"properties\":{\n",
    "                                    \"answer\":{\"type\":\"string\"},\n",
    "                                    \"correct\": {\"type\": \"boolean\"}\n",
    "                                }\n",
    "                            },\n",
    "                            \"required\": [\"answer\", \"correct\"],\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"question\", \"answers\"],\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"questions\"],\n",
    "    }\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1, ).bind(function_call={\"name\":\"create_quiz\"},\n",
    "                                         functions=[function])\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"Make a quiz about {city}.\\\n",
    "                                      each answers have five answer. one correct answer and four false answer\")\n",
    "chain = prompt | llm\n",
    "response = chain.invoke({\"city\":\"Seoul\"})\n",
    "\n",
    "response = response#.additional_kwargs#[\"function_call\"][\"arguments\"]\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'questions': [{'question': 'What is the capital city of South Korea?',\n",
       "   'answers': [{'answer': 'Busan', 'correct': False},\n",
       "    {'answer': 'Incheon', 'correct': False},\n",
       "    {'answer': 'Seoul', 'correct': True},\n",
       "    {'answer': 'Daegu', 'correct': False},\n",
       "    {'answer': 'Gwangju', 'correct': False}]},\n",
       "  {'question': 'Which river flows through Seoul?',\n",
       "   'answers': [{'answer': 'Han River', 'correct': True},\n",
       "    {'answer': 'Nakdong River', 'correct': False},\n",
       "    {'answer': 'Geum River', 'correct': False},\n",
       "    {'answer': 'Yeongsan River', 'correct': False},\n",
       "    {'answer': 'Taedong River', 'correct': False}]},\n",
       "  {'question': 'What is the tallest building in Seoul?',\n",
       "   'answers': [{'answer': 'Lotte World Tower', 'correct': True},\n",
       "    {'answer': '63 Building', 'correct': False},\n",
       "    {'answer': 'N Seoul Tower', 'correct': False},\n",
       "    {'answer': 'Seoul Sky', 'correct': False},\n",
       "    {'answer': 'COEX Tower', 'correct': False}]},\n",
       "  {'question': 'Which palace is located in the heart of Seoul?',\n",
       "   'answers': [{'answer': 'Gyeongbokgung Palace', 'correct': True},\n",
       "    {'answer': 'Changdeokgung Palace', 'correct': False},\n",
       "    {'answer': 'Deoksugung Palace', 'correct': False},\n",
       "    {'answer': 'Changgyeonggung Palace', 'correct': False},\n",
       "    {'answer': 'Gyeonghuigung Palace', 'correct': False}]},\n",
       "  {'question': 'What is the traditional Korean market in Seoul?',\n",
       "   'answers': [{'answer': 'Namdaemun Market', 'correct': True},\n",
       "    {'answer': 'Dongdaemun Market', 'correct': False},\n",
       "    {'answer': 'Gwangjang Market', 'correct': False},\n",
       "    {'answer': 'Seoul Folk Flea Market', 'correct': False},\n",
       "    {'answer': 'Myeongdong Market', 'correct': False}]}]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the capital city of South Korea?\n",
      "Seoul\n",
      "Which river flows through Seoul?\n",
      "Han River\n",
      "What is the tallest building in Seoul?\n",
      "Lotte World Tower\n",
      "Which palace is located in the heart of Seoul?\n",
      "Gyeongbokgung Palace\n",
      "What is the famous shopping district in Seoul?\n",
      "Myeongdong\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "for question in json.loads(response)[\"questions\"]:\n",
    "    print(question[\"question\"])\n",
    "    for answer in question[\"answers\"]:\n",
    "        #print(question[\"question\"])\n",
    "        \n",
    "        #print(answer[\"answer\"])\n",
    "        if answer == {\"answer\": answer[\"answer\"],\"correct\": True}:\n",
    "            print(answer[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
